import streamlit as st
import requests
import json
import base64
import os

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í•™ì  íŒŒíŠ¸ë„ˆ", page_icon="ğŸ«")
st.title("ğŸ« í•™ì  íŒŒíŠ¸ë„ˆ")

# 2. API í‚¤ í™•ì¸
if "GEMINI_API_KEY" not in st.secrets:
    st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

API_KEY = st.secrets["GEMINI_API_KEY"]

# 3. ì±„íŒ… í•¨ìˆ˜ (AI Studio í‚¤ ì „ìš©)
def call_gemini(prompt, pdf_files):
    # AI Studio í‚¤ëŠ” ì´ ëª¨ë¸ì´ 100% ì‘ë™í•©ë‹ˆë‹¤. (ì´ë¦„ ë³€ê²½ ê¸ˆì§€)
    model_name = "models/gemini-1.5-flash"
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={API_KEY}"
    
    system_instruction = """
    ë‹¹ì‹ ì€ í•™êµ í•™ì  ì—…ë¬´ë¥¼ ì§€ì›í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
    ë‹µë³€ì€ ì œê³µëœ ë¬¸ì„œì— ê¸°ë°˜í•´ì•¼ í•˜ë©°, ë‹µë³€ ëì— (ë¬¸ì„œëª…, í˜ì´ì§€)ë¥¼ ì¶œì²˜ë¡œ ë‚¨ê²¨ì•¼ í•©ë‹ˆë‹¤.
    """
    
    parts = [{"text": system_instruction}, {"text": f"ì§ˆë¬¸: {prompt}"}]
    
    # PDF ì²¨ë¶€
    if pdf_files:
        for pdf_path in pdf_files:
            try:
                with open(pdf_path, "rb") as f:
                    pdf_data = base64.b64encode(f.read()).decode("utf-8")
                    parts.append({
                        "inline_data": {
                            "mime_type": "application/pdf",
                            "data": pdf_data
                        }
                    })
            except:
                pass

    payload = {"contents": [{"parts": parts}]}
    
    response = requests.post(
        url, 
        headers={"Content-Type": "application/json"}, 
        data=json.dumps(payload),
        timeout=30
    )
    return response

# PDF íŒŒì¼ ì°¾ê¸°
pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf')]

# 4. í™”ë©´ í‘œì‹œ
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í•™ì  ê·œì •ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        msg_box = st.empty()
        msg_box.markdown("ìƒì„± ì¤‘... â³")
        
        try:
            res = call_gemini(prompt, pdf_files)
            
            if res.status_code == 200:
                ans = res.json()['candidates'][0]['content']['parts'][0]['text']
                msg_box.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans})
            else:
                # ì—ëŸ¬ ë°œìƒ ì‹œ ì›ì¸ ì¶œë ¥
                msg_box.error(f"ì˜¤ë¥˜: {res.status_code}")
                st.json(res.json())
        except Exception as e:
            msg_box.error(f"ì—ëŸ¬: {e}")
